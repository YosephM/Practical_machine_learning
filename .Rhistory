demo()
install.packages(c("BMA", "digest", "robustbase", "tree"))
a<-available.packages();
a
head(a)
clear
cls
head(rowname(a),3
head(rowname(a),3)
fileUrl = "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl,destfile="cameras.xlsx",mode="wb")
library(xlsx)
list.files("./data")
getwd()
fileUrl = "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
download.file(fileUrl,destfile="cameras.xlsx",mode="wb")
dataDownloaded <-date()
download.file(fileUrl,destfile="cameras.xlsx")
?rbinom
install.packages("swirl")
library("swirl")
swirl()
install.packages("Knitr")
install.packages("Knitr")
install.packages("knitr")
Title
this is a title i'm working on
```{r}
install.packages('pdflatex')
install.packages('Tex')
install.packages('pandoc')
data(mtcars)
data(mtcars)
mtcars$am <- factor(mtcars$am)
levels(mtcars$am) <- c("automatic", "manual")
automaticMPG <- mtcars$mpg[mtcars$am == "automatic"]
manualMPG <- mtcars$mpg[mtcars$am == "manual"]
automaticLn<-lm(mpg ~ wt, data=automaticMPG)
automaticLn<-lm(mpg ~ wt, data=automaticMPG)
manualLn<-lm(mpg ~ wt, data=manualMPG)
str(automaticMPG)
colnames(automaticMPG)
mtcarsAutomatic<-mtcars[mtcars$am=="automatic",]
mtcarsManual<-mtcars[mtcars$am=="manual",]
automaticLn<-lm(mpg ~ wt, data=mtcarsAutomatic)
manualLn<-lm(mpg ~ wt, data=mtcarsManual)
plot(mtcars$wt,mtcars$mpg,col=mtcars$am,xlim=c(0,6),ylim=c(0,50))
abline(automaticLn,col="black")
abline(manualLn,col="red")
text(x=4.5,y=40,labels=c("manual = Red"),col="red",cex=0.75,pos=4)
text(x=4.5,y=37,labels=c("automatic = Black"),col="black",cex=0.75,pos=4)
par(mfrow=c(1,1))
plot(mtcars$wt,mtcars$mpg,col=mtcars$am,xlim=c(0,6),ylim=c(0,50))
abline(automaticLn,col="black")
abline(manualLn,col="red")
text(x=4.5,y=40,labels=c("manual = Red"),col="red",cex=0.75,pos=4)
text(x=4.5,y=37,labels=c("automatic = Black"),col="black",cex=0.75,pos=4)
plot(mtcars$wt,mtcars$mpg,col=mtcars$am,xlim=c(0,6),ylim=c(0,50))
m_int <- lm(mpg ~ am + wt + am*wt, data=mtcars)
plot(mtcars$wt,mtcars$mpg,col=mtcars$am,xlim=c(0,6),ylim=c(0,50),xlab="Weight", ylab="MPG")
abline(automaticLn,col="green")
abline(manualLn,col="blue")
abline(m_int$coef[2] + m_int$coef[4]*mtcars$wt, col="black")
text(x=4.5,y=40,labels=c("manual = Blue"),col="blue",cex=0.75,pos=4)
text(x=4.5,y=37,labels=c("automatic = Green"),col="green",cex=0.75,pos=4)
par(mfrow=c(1,1))
plot(mtcars$wt,mtcars$mpg,col=mtcars$am,xlim=c(0,6),ylim=c(0,50),xlab="Weight", ylab="MPG")
abline(automaticLn,col="green")
abline(manualLn,col="blue")
abline(m_int$coef[2] + m_int$coef[4]*mtcars$wt, col="black")
text(x=4.5,y=40,labels=c("manual = Blue"),col="blue",cex=0.75,pos=4)
text(x=4.5,y=37,labels=c("automatic = Green"),col="green",cex=0.75,pos=4)
resultLn<- lm(m_int$coef[2] + m_int$coef[4]*mtcars$wt ~ wt, mtcarsAutomatic)
m_int <- lm(mpg ~ am + wt + am*wt, data=mtcars)
resultLn<- lm(m_int$coef[2] + m_int$coef[4]*mtcars$wt ~ wt, mtcarsAutomatic)
resultLn<- lm(m_int$coef[2] + m_int$coef[4]*mtcars$wt ~ wt, mtcars)
install.packages("shinyapps")
install.packages("devtools")
install.packages("shinyapps")
package.install("catet")
package.install("caret")
install.packages("caret")
library(caret)
library(caret)
getwd()
setwd("D:/trainings/developingDataProducs")
setwd("D:/trainings/developingDataProducts")
setwd("deck1")
getwd()
install.packages("markdown")
library(markdown)
library(markdown)
rpubsUpload("testingShiny","index.html",id=NULL,properties = list(),method=getOption("rpubs.upload.method", "internal"))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
predictors
diagnosis
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cut2()?
lkad
library(ggplot2)
library(Hmisc)
inTrain$index
training$index
colnames(mixtures)
head(mixture)
head(mixtures)
summery(mixtures)
summary(mixtures)
featurePlot(x=training[,"Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer","CoarseAggregate", "FineAggregate","Age"], y=training$CompressiveStrength, plot="pairs")
featurePlot(x=training[,c("Cement","BlastFurnaceSlag","FlyAsh","Water","Superplasticizer","CoarseAggregate", "FineAggregate","Age")], y=training$CompressiveStrength, plot="pairs")
head(training)
Human Activity Recognition - HAR - has emerged as a key research area in the last years and is gaining increasing attention by the pervasive computing research community, especially for the development of context-aware systems. There are many potential applications for HAR, like: elderly monitoring, life log systems for monitoring energy expenditure and for supporting weight-loss programs, and digital assistants for weight lifting exercises.
getwd()
setwd("D:\Trainings\Practical-Machine\courseProject")
setwd("D:/Trainings/Practical-Machine/courseProject")
raw_training <- read.csv("pml-training.csv")
raw_training <- read.csv("data/pml-training.csv")
if (!file.exists("data/pml-training.csv")) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
destfile="data/pml-training.csv", method="curl")
}
if (!file.exists("data/pml-testing.csv")) {
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="data/pml-testing.csv", method="curl")
}
testing  <- read.csv("data/pml-testing.csv")
raw_training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(raw_training)
testing  <- read.csv("data/pml-testing.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(testing)
colnames(testing)
training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(training)
library(caret)
index <- createDataPartition(training$classe, p=.50, list=FALSE)
training.train <-training[index,]
training.validate <- training[-index,]
Summery(training)
Summary(training)
Summery(training)
summery(training)
summary(training)
summary(training)
nsv <- nearZeroVar(training2, freqCut = 95/5, saveMetrics=TRUE)
nsv <- nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
not_nsv <- subset(nsv, nsv$nzv == FALSE)
not_nsv
nsv
nsv[-nzv==FALSE]
nsv[-nzv==FALSE,]
nsv[,-nzv==FALSE]
nsv[,-(nzv==FALSE)]
nsv[,-(nsv$nzv==FALSE)]
nsv[,(nsv$nzv==FALSE)]
nsv[nsv$nzv==FALSE,]
rownames(nsv[nsv$nzv==FALSE,])
index <- createDataPartition(training$classe, p=3/4, list=FALSE)
index
index <- createDataPartition(training$classe, p=.75, list=FALSE)
index
training.train <-training[index,]
training.validate <- training[-index,]
round(prop.table(table(training.train$classe))*100, digits = 1)
table(training.train$classe)
summary(trainiing.train$class)
summary(training.train$class)
summary(training.train$Class)
summary(training.train$Class)
summary(training.validate$class)
summary(training.train$class)
summary(training.validate$class)
training <- training[colSums(is.na(training)) < 1]
training <- training[colSums(is.na(training)) < 1]
# Extracting near zero variables
nearZero <- nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
training <- training[rownames(nearZero[nearZero==FALSE,])]
#Splitting into training and validation sets
library(caret)
index <- createDataPartition(training$classe, p=.75, list=FALSE)
training.train <-training[index,]
training.validate <- training[-index,]
nearZero <- nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
training <- training[rownames(nearZero[nearZero$nzv==FALSE,])]
opts_chunk$set( warning=FALSE, message=FALSE)
opts_knit$set( warning=FALSE, message=FALSE)
knitr::opts_chunk$set( warning=FALSE, message=FALSE)
library(ggplot2)
featurePlot(x=training[,c(1:8)], y=training$class, plot="pairs")
featurePlot(x=training[,c(1:14)], y=training$class, plot="pairs")
corelatedIndexes <- caret::findCorrelation(cor(training[,1-60]), cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,1:60]), cutoff=0.8)
rownames(training)
columnNames(training)
colNames(training)
cols(training)
colnames(training)
corelatedIndexes <- caret::findCorrelation(cor(training[,1:59]), cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,1:59]), cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,8:59]), cutoff=0.8)
cor(training[,8:59])
dim(training.validate)
dim(training.train)
corelatedIndexes <- caret::findCorrelation(cor(training.train[,8:60]), cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training.train), cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(rcorr(training, type="pearson") ,cutoff=0.8)
training$class<-factor(training$classe)
training$user_name <- factor(training$user_name)
corelatedIndexes <- caret::findCorrelation(rcorr(training, type="pearson") ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training, type="pearson") ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training) ,cutoff=0.8)
training
corelatedIndexes <- caret::findCorrelation(cor([training],-c(59,60)) ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(59,60)]) ,cutoff=0.8)
head(training)
colnames(training)
length(colnames(training))
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,59,60)]) ,cutoff=0.8)
colnames(tarining[,-c(1,2,59,60)])
colnames(training[,-c(1,2,59,60)])
head(training[,-c(1,2,59,60)])
summary(training[,-c(1,2,59,60)])
summary(training[,-c(1,2,3,4,5,59,60)])
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,3,4,5,59,60)]) ,cutoff=0.8)
corelatedIndexes
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,3,4,5,59,6)]) ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,3,4,5,59)]) ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,3,4,5,60)]) ,cutoff=0.8)
corelatedIndexes <- caret::findCorrelation(cor(training[,-c(1,2,3,4,5,59,60)]) ,cutoff=0.8)
corelatedIndexes
rownames(nearZero[nearZero$nzv == FALSE,])
nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
colnames(training)
nearZero
training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
colnames(training)
dim(training)
training <- training[colSums(is.na(training)) < 1]
colnames(training)
nearZero <- nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
training <- training[rownames(nearZero[nearZero$nzv == FALSE,])]
colnames(training)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="data/pml-testing.csv", method="wget")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="data/pml-testing.csv", method="wget")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="data/pml-testing.csv", method="curl")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv",
destfile="data/pml-testing.csv", method="auto")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv",
destfile="data/pml-training.csv", method="auto")
training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(training)
training <- training[colSums(is.na(training)) < 1]
nearZero <- nearZeroVar(training, freqCut = 95/5, saveMetrics=TRUE)
training <- training[rownames(nearZero[nearZero$nzv == FALSE,])]
colname(training)
colnames(training)
training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(training)
testing  <- read.csv("data/pml-testing.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(testing)
training <- training[colSums(is.na(training)) < 1]
colnames(training)
training <- read.csv("data/pml-training.csv", na.strings = c("", "NA", "#DIV/0!") )
dim(training)
colSums(is.na(training))
length(colSums(is.na(training)))
